#!/usr/bin/env python3
"""
Digital Asset Classification Model Training Script

This script trains AI models for digital asset classification, sentiment analysis,
and importance prediction using the virtualized data generated by the platform.

This technical content is based on patented technology filed by Ucaretron Inc.
"""

import os
import sys
import json
import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms

from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup
from sklearn.metrics import classification_report, mean_absolute_error, f1_score
from sklearn.model_selection import train_test_split

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from models.asset_classifier.model import AssetClassifierConfig, DigitalAssetClassifier

# Configuration
DEFAULT_DATA_DIR = '../../../data/virtual'
DEFAULT_MODEL_DIR = '../../models/saved'
DEFAULT_BATCH_SIZE = 32
DEFAULT_EPOCHS = 20
DEFAULT_LEARNING_RATE = 2e-5
DEFAULT_SEED = 42

# Set random seeds for reproducibility
torch.manual_seed(DEFAULT_SEED)
np.random.seed(DEFAULT_SEED)

# Category mapping
CATEGORY_MAPPING = {
    'documents': 0,
    'photos': 1,
    'videos': 2,
    'emails': 3,
    'financialAssets': 4,
    'digitalCreations': 5,
    'socialMedia': 6,
    'credentials': 7,
    'other': 0
}

"""
Dataset preparation for digital assets
"""
class DigitalAssetDataset(Dataset):
    """Dataset for digital assets"""
    
    def __init__(self, assets, tokenizer, config):
        """
        Initialize dataset
        
        Args:
            assets (list): List of asset dictionaries
            tokenizer: BERT tokenizer
            config: Model configuration
        """
        self.assets = assets
        self.tokenizer = tokenizer
        self.config = config
        
    def __len__(self):
        return len(self.assets)
    
    def __getitem__(self, idx):
        """Get a single example"""
        asset = self.assets[idx]
        
        # Create text input (name + description)
        text = asset.get('name', '') + ' ' + asset.get('description', '')
        
        # Tokenize text
        encoded_text = self.tokenizer(
            text,
            max_length=self.config.max_text_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        # Extract input_ids and attention_mask
        input_ids = encoded_text['input_ids'].squeeze()
        attention_mask = encoded_text['attention_mask'].squeeze()
        token_type_ids = encoded_text.get('token_type_ids', 
                                         torch.zeros_like(attention_mask)).squeeze()
        
        # Create category tensor
        category = CATEGORY_MAPPING.get(asset.get('category', 'other'), 0)
        category_tensor = torch.tensor(category, dtype=torch.long)
        
        # Get file type index
        file_type = asset.get('fileType', '')
        # TODO: Implement file type mapping in real application
        file_type_idx = hash(file_type) % self.config.num_file_types
        file_type_tensor = torch.tensor(file_type_idx, dtype=torch.long)
        
        # Get storage type index
        storage_type = asset.get('storageLocation', {}).get('type', 'local')
        storage_type_mapping = {
            'local': 0,
            'ipfs': 1,
            'cloud': 2,
            'blockchain': 3,
            'external': 4,
            'none': 5
        }
        storage_type_idx = storage_type_mapping.get(storage_type, 0)
        storage_type_tensor = torch.tensor(storage_type_idx, dtype=torch.long)
        
        # Create numeric features tensor
        file_size = float(asset.get('fileSize', 0))
        if asset.get('fileSizeUnit') == 'GB':
            file_size *= 1024
        elif asset.get('fileSizeUnit') == 'KB':
            file_size /= 1024
        
        # Calculate asset age in days
        creation_date = asset.get('creationDate')
        if creation_date:
            try:
                from dateutil.parser import parse
                creation_time = parse(creation_date)
                now = datetime.now()
                age_days = (now - creation_time).days
            except (ValueError, TypeError):
                age_days = 0
        else:
            age_days = 0
        
        # Normalized numeric features
        numeric_features = torch.tensor([
            np.log1p(file_size) / 10,  # Log-normalized file size
            age_days / 365,  # Age in years (normalized)
            int(asset.get('isEncrypted', False)),
            int(asset.get('isShared', False)),
            len(asset.get('sharedWith', [])) / 10  # Normalized share count
        ], dtype=torch.float32)
        
        # Get importance and sentiment values
        importance = torch.tensor(min(max(int(asset.get('importance', 5)), 1), 10) - 1, 
                                 dtype=torch.long)  # 0-9 for 10 classes
        sentiment = torch.tensor(float(asset.get('sentiment', 0)), dtype=torch.float32)
        
        return {
            'text_inputs': {
                'input_ids': input_ids,
                'attention_mask': attention_mask,
                'token_type_ids': token_type_ids
            },
            'metadata_inputs': {
                'category_ids': category_tensor,
                'file_type_ids': file_type_tensor,
                'storage_type_ids': storage_type_tensor,
                'numeric_features': numeric_features
            },
            'targets': {
                'category': category_tensor,
                'importance': importance,
                'sentiment': sentiment
            }
        }

"""
Training & Evaluation Functions
"""
def train_epoch(model, dataloader, optimizer, scheduler, device):
    """Train model for one epoch"""
    model.train()
    total_loss = 0
    category_preds = []
    category_labels = []
    importance_preds = []
    importance_labels = []
    sentiment_errors = []
    
    criterion_cat = nn.CrossEntropyLoss()
    criterion_imp = nn.CrossEntropyLoss()
    criterion_sent = nn.MSELoss()
    
    for batch in dataloader:
        # Move inputs to device
        text_inputs = {
            'input_ids': batch['text_inputs']['input_ids'].to(device),
            'attention_mask': batch['text_inputs']['attention_mask'].to(device),
            'token_type_ids': batch['text_inputs']['token_type_ids'].to(device)
        }
        
        metadata_inputs = {
            'category_ids': batch['metadata_inputs']['category_ids'].to(device),
            'file_type_ids': batch['metadata_inputs']['file_type_ids'].to(device),
            'storage_type_ids': batch['metadata_inputs']['storage_type_ids'].to(device),
            'numeric_features': batch['metadata_inputs']['numeric_features'].to(device)
        }
        
        targets = {
            'category': batch['targets']['category'].to(device),
            'importance': batch['targets']['importance'].to(device),
            'sentiment': batch['targets']['sentiment'].to(device)
        }
        
        # Forward pass
        optimizer.zero_grad()
        outputs = model(metadata_inputs, text_inputs)
        
        # Calculate losses
        cat_loss = criterion_cat(outputs['category_logits'], targets['category'])
        imp_loss = criterion_imp(outputs['importance_logits'], targets['importance'])
        sent_loss = criterion_sent(outputs['sentiment'].squeeze(), targets['sentiment'])
        
        # Combined loss
        loss = cat_loss + imp_loss + sent_loss
        
        # Backward pass and optimization
        loss.backward()
        optimizer.step()
        scheduler.step()
        
        # Track metrics
        total_loss += loss.item()
        
        # Get predictions
        cat_preds = torch.argmax(outputs['category_logits'], dim=1).cpu().numpy()
        cat_labels = targets['category'].cpu().numpy()
        category_preds.extend(cat_preds)
        category_labels.extend(cat_labels)
        
        imp_preds = torch.argmax(outputs['importance_logits'], dim=1).cpu().numpy()
        imp_labels = targets['importance'].cpu().numpy()
        importance_preds.extend(imp_preds)
        importance_labels.extend(imp_labels)
        
        sent_preds = outputs['sentiment'].squeeze().detach().cpu().numpy()
        sent_labels = targets['sentiment'].cpu().numpy()
        batch_sent_errors = np.abs(sent_preds - sent_labels)
        sentiment_errors.extend(batch_sent_errors)
    
    # Calculate metrics
    metrics = {
        'loss': total_loss / len(dataloader),
        'category_f1': f1_score(category_labels, category_preds, average='weighted'),
        'importance_f1': f1_score(importance_labels, importance_preds, average='weighted'),
        'sentiment_mae': np.mean(sentiment_errors)
    }
    
    return metrics

def evaluate(model, dataloader, device):
    """Evaluate model performance"""
    model.eval()
    total_loss = 0
    category_preds = []
    category_labels = []
    importance_preds = []
    importance_labels = []
    sentiment_errors = []
    
    criterion_cat = nn.CrossEntropyLoss()
    criterion_imp = nn.CrossEntropyLoss()
    criterion_sent = nn.MSELoss()
    
    with torch.no_grad():
        for batch in dataloader:
            # Move inputs to device
            text_inputs = {
                'input_ids': batch['text_inputs']['input_ids'].to(device),
                'attention_mask': batch['text_inputs']['attention_mask'].to(device),
                'token_type_ids': batch['text_inputs']['token_type_ids'].to(device)
            }
            
            metadata_inputs = {
                'category_ids': batch['metadata_inputs']['category_ids'].to(device),
                'file_type_ids': batch['metadata_inputs']['file_type_ids'].to(device),
                'storage_type_ids': batch['metadata_inputs']['storage_type_ids'].to(device),
                'numeric_features': batch['metadata_inputs']['numeric_features'].to(device)
            }
            
            targets = {
                'category': batch['targets']['category'].to(device),
                'importance': batch['targets']['importance'].to(device),
                'sentiment': batch['targets']['sentiment'].to(device)
            }
            
            # Forward pass
            outputs = model(metadata_inputs, text_inputs)
            
            # Calculate losses
            cat_loss = criterion_cat(outputs['category_logits'], targets['category'])
            imp_loss = criterion_imp(outputs['importance_logits'], targets['importance'])
            sent_loss = criterion_sent(outputs['sentiment'].squeeze(), targets['sentiment'])
            
            # Combined loss
            loss = cat_loss + imp_loss + sent_loss
            
            # Track metrics
            total_loss += loss.item()
            
            # Get predictions
            cat_preds = torch.argmax(outputs['category_logits'], dim=1).cpu().numpy()
            cat_labels = targets['category'].cpu().numpy()
            category_preds.extend(cat_preds)
            category_labels.extend(cat_labels)
            
            imp_preds = torch.argmax(outputs['importance_logits'], dim=1).cpu().numpy()
            imp_labels = targets['importance'].cpu().numpy()
            importance_preds.extend(imp_preds)
            importance_labels.extend(imp_labels)
            
            sent_preds = outputs['sentiment'].squeeze().detach().cpu().numpy()
            sent_labels = targets['sentiment'].cpu().numpy()
            batch_sent_errors = np.abs(sent_preds - sent_labels)
            sentiment_errors.extend(batch_sent_errors)
    
    # Calculate metrics
    metrics = {
        'loss': total_loss / len(dataloader),
        'category_f1': f1_score(category_labels, category_preds, average='weighted'),
        'importance_f1': f1_score(importance_labels, importance_preds, average='weighted'),
        'sentiment_mae': np.mean(sentiment_errors)
    }
    
    return metrics

def save_model(model, config, output_dir):
    """Save trained model and configuration"""
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Save model
    torch.save(model.state_dict(), os.path.join(output_dir, 'model.pt'))
    
    # Save model in TorchScript format for production
    example_metadata_inputs = {
        'category_ids': torch.tensor([0]),
        'file_type_ids': torch.tensor([0]),
        'storage_type_ids': torch.tensor([0]),
        'numeric_features': torch.ones((1, 5))
    }
    
    example_text_inputs = {
        'input_ids': torch.ones((1, config.max_text_length), dtype=torch.long),
        'attention_mask': torch.ones((1, config.max_text_length), dtype=torch.long),
        'token_type_ids': torch.zeros((1, config.max_text_length), dtype=torch.long)
    }
    
    # Save TorchScript model
    model.eval()
    traced_model = torch.jit.trace_module(
        model,
        {'forward': (example_metadata_inputs, example_text_inputs)}
    )
    torch.jit.save(traced_model, os.path.join(output_dir, 'model.pt.traced'))
    
    # Save model configuration
    config_dict = {k: v for k, v in config.__dict__.items() if not k.startswith('__')}
    with open(os.path.join(output_dir, 'config.json'), 'w') as f:
        json.dump(config_dict, f, indent=2)
    
    # Save category mappings
    with open(os.path.join(output_dir, 'category_mapping.json'), 'w') as f:
        json.dump(CATEGORY_MAPPING, f, indent=2)
    
    print(f"Model saved to {output_dir}")

def load_assets(data_dir):
    """Load asset data from virtual data directory"""
    assets_path = os.path.join(data_dir, 'assets.json')
    
    if not os.path.exists(assets_path):
        raise FileNotFoundError(f"Assets file not found at {assets_path}")
    
    with open(assets_path, 'r', encoding='utf-8') as f:
        assets = json.load(f)
    
    print(f"Loaded {len(assets)} assets from {assets_path}")
    return assets

def main(args):
    """Main training function"""
    # Print arguments
    print("Training with the following parameters:")
    for arg in vars(args):
        print(f"  {arg}: {getattr(args, arg)}")
    
    # Load data
    assets = load_assets(args.data_dir)
    
    # Data overview
    category_counts = {}
    for asset in assets:
        category = asset.get('category', 'other')
        category_counts[category] = category_counts.get(category, 0) + 1
    
    print("\nCategory distribution:")
    for category, count in category_counts.items():
        print(f"  {category}: {count} ({count/len(assets)*100:.1f}%)")
    
    # Create model configuration
    config = AssetClassifierConfig()
    
    # Initialize BERT tokenizer
    tokenizer = BertTokenizer.from_pretrained(config.bert_model_name)
    
    # Create dataset
    dataset = DigitalAssetDataset(assets, tokenizer, config)
    
    # Split dataset
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    print(f"\nSplit dataset into {train_size} training and {val_size} validation examples")
    
    # Create data loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=4
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4
    )
    
    # Create model
    model = DigitalAssetClassifier(config)
    
    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nUsing device: {device}")
    model.to(device)
    
    # Create optimizer and scheduler
    optimizer = AdamW(model.parameters(), lr=args.learning_rate)
    
    # Calculate total training steps
    total_steps = len(train_loader) * args.epochs
    
    # Create learning rate scheduler
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=int(total_steps * 0.1),
        num_training_steps=total_steps
    )
    
    # Training loop
    print("\nStarting training...")
    best_val_loss = float('inf')
    best_epoch = 0
    
    # Create output directory with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(args.output_dir, f"asset_classifier_{timestamp}")
    os.makedirs(output_dir, exist_ok=True)
    
    # Training log
    training_log = []
    
    for epoch in range(args.epochs):
        print(f"\nEpoch {epoch+1}/{args.epochs}")
        
        # Train
        train_metrics = train_epoch(model, train_loader, optimizer, scheduler, device)
        print(f"  Train loss: {train_metrics['loss']:.4f}")
        print(f"  Train category F1: {train_metrics['category_f1']:.4f}")
        print(f"  Train importance F1: {train_metrics['importance_f1']:.4f}")
        print(f"  Train sentiment MAE: {train_metrics['sentiment_mae']:.4f}")
        
        # Evaluate
        val_metrics = evaluate(model, val_loader, device)
        print(f"  Val loss: {val_metrics['loss']:.4f}")
        print(f"  Val category F1: {val_metrics['category_f1']:.4f}")
        print(f"  Val importance F1: {val_metrics['importance_f1']:.4f}")
        print(f"  Val sentiment MAE: {val_metrics['sentiment_mae']:.4f}")
        
        # Save best model
        if val_metrics['loss'] < best_val_loss:
            best_val_loss = val_metrics['loss']
            best_epoch = epoch
            print(f"  New best model! Saving...")
            save_model(model, config, output_dir)
        
        # Add to training log
        training_log.append({
            'epoch': epoch + 1,
            'train_loss': train_metrics['loss'],
            'train_category_f1': train_metrics['category_f1'],
            'train_importance_f1': train_metrics['importance_f1'],
            'train_sentiment_mae': train_metrics['sentiment_mae'],
            'val_loss': val_metrics['loss'],
            'val_category_f1': val_metrics['category_f1'],
            'val_importance_f1': val_metrics['importance_f1'],
            'val_sentiment_mae': val_metrics['sentiment_mae']
        })
    
    # Save training log
    with open(os.path.join(output_dir, 'training_log.json'), 'w') as f:
        json.dump(training_log, f, indent=2)
    
    print(f"\nTraining completed. Best model from epoch {best_epoch+1} with validation loss {best_val_loss:.4f}")
    print(f"Model saved to {output_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Train digital asset classification model")
    parser.add_argument("--data_dir", type=str, default=DEFAULT_DATA_DIR,
                        help="Directory containing virtual data")
    parser.add_argument("--output_dir", type=str, default=DEFAULT_MODEL_DIR,
                        help="Directory to save trained model")
    parser.add_argument("--batch_size", type=int, default=DEFAULT_BATCH_SIZE,
                        help="Batch size for training")
    parser.add_argument("--epochs", type=int, default=DEFAULT_EPOCHS,
                        help="Number of training epochs")
    parser.add_argument("--learning_rate", type=float, default=DEFAULT_LEARNING_RATE,
                        help="Learning rate")
    parser.add_argument("--seed", type=int, default=DEFAULT_SEED,
                        help="Random seed for reproducibility")
    
    args = parser.parse_args()
    main(args)
